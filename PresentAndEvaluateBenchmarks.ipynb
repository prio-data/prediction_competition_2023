{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0573b9c2",
   "metadata": {},
   "source": [
    "# Presenting and evaluating benchmark models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3094fc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4857d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cbook as cbook\n",
    "import os\n",
    "\n",
    "# Evaluation scripts\n",
    "from CompetitionEvaluation import load_data, structure_data, calculate_metrics\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edd77af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where to find files\n",
    "username = os.getlogin()\n",
    "Mydropbox = f'/Users/{username}/Dropbox (ViEWS)/ViEWS/'\n",
    "overleafpath = f'/Users/{username}/Dropbox (ViEWS)/Apps/Overleaf/Prediction competition 2023/Tables/'\n",
    "overleafpath_figures = f'/Users/{username}/Dropbox (ViEWS)/Apps/Overleaf/Prediction competition 2023/Figures/'\n",
    "print('Dropbox path set to',Mydropbox)\n",
    "print('Overleaf path set to',overleafpath)\n",
    "\n",
    "filepath = Mydropbox + 'Prediction_competition_2023/' \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2bf775",
   "metadata": {},
   "source": [
    "## Reading in actuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c1be9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cm_actuals = pd.read_parquet(filepath + 'cm_actuals_allyears.parquet')\n",
    "df_pgm_actuals = pd.read_parquet(filepath + 'pgm_actuals_allyears.parquet')\n",
    "df_cm_actuals.tail(), df_pgm_actuals.head()\n",
    "# Recast to int32\n",
    "df_cm_actuals['ged_sb'] = df_cm_actuals['ged_sb'].astype('int32')\n",
    "df_pgm_actuals['ged_sb'] = df_pgm_actuals['ged_sb'].astype('int32')\n",
    "df_pgm_actuals.index.set_names('priogrid_gid', level=1,inplace=True)\n",
    "# Have to rename column name....:\n",
    "df_cm_actuals.rename(columns={\"ged_sb\": \"outcome\"}, errors=\"raise\", inplace=True)\n",
    "df_pgm_actuals.rename(columns={\"ged_sb\": \"outcome\"}, errors=\"raise\", inplace=True)\n",
    "# Summarize:\n",
    "print(df_cm_actuals.dtypes, df_pgm_actuals.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb9a5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cm_actuals.describe(percentiles=[.25,.50,.75,.90,.95,.99,.992,.995])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88954d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from viewser import Queryset, Column\n",
    "qs = (Queryset(\"country_list\", \"country_month\")\n",
    "\n",
    "   .with_column(Column(\"id\", from_table=\"country\", from_column=\"id\"))\n",
    "   .with_column(Column(\"name\", from_table=\"country\", from_column=\"name\"))\n",
    "              \n",
    "   )\n",
    "countrylist = qs.publish().fetch().loc[504]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8484fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "countrylist.loc[69]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063d5877",
   "metadata": {},
   "source": [
    "## Reading in benchmark prediction models: \n",
    "\n",
    "Two models per level:\n",
    "\n",
    "1. cm model, based on ensemble\n",
    "2. cm model, based on historical values \n",
    "3. pgm model, based on ensemble\n",
    "4. pgm model, based on historical values\n",
    "\n",
    "Ã‹ach of these have predictions for each of four years; 2019, 2020, 2021, and 2022. The four years are collected in lists of dictionaries including dataframes and some metadata, one for each of the models above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3af0ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_cm_actuals.query('country_id == 57'))\n",
    "df_cm_actuals.loc[445:468]\n",
    "df_cm_actuals.head()\n",
    "df_cm_actuals.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fd09a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm_cm_ensemble_poisson = []\n",
    "bm_cm_ensemble_identical = []\n",
    "bm_cm_constituent_poisson = []\n",
    "bm_cm_actuals_bootstrap = []\n",
    "bm_cm_last_historical_poisson= []\n",
    "\n",
    "model_names = ['ensemble_poisson','ensemble_identical','constituent_poisson','bootstrap','last_historical_poisson']\n",
    "\n",
    "bm_pgm_ensemble_poisson = []\n",
    "bm_pgm_ensemble_identical = []\n",
    "bm_pgm_historical_values = []\n",
    "model_names = ['ensemble_poisson','ensemble_identical']\n",
    "\n",
    "include_historical_values = True\n",
    "include_constituent = True\n",
    "include_pgm = True\n",
    "\n",
    "def positive_integers(df, colname):\n",
    "    df[colname] = np.round(df[colname]).astype('int32')\n",
    "    df[colname][df[colname] < 0] = 0\n",
    "    return(df)\n",
    "\n",
    "colname = 'prediction'\n",
    "colname = 'outcome'\n",
    "for year in [2018, 2019, 2020, 2021]:\n",
    "    print(year)\n",
    "    first_month = (year - 1980)*12 + 1\n",
    "    cm_e = {\n",
    "        'year': year,\n",
    "        'first_month': first_month,\n",
    "        'name': 'cm_ensemble_poisson',\n",
    "        'df_full': positive_integers(pd.read_parquet(filepath + 'bm_cm_ensemble_poisson_expanded_' + str(year) + '.parquet'),colname),\n",
    "        'actuals': df_cm_actuals.loc[first_month: first_month + 12 - 1],\n",
    "    }\n",
    "    bm_cm_ensemble_poisson.append(cm_e)\n",
    "    \n",
    "    cm_e = {\n",
    "        'year': year,\n",
    "        'first_month': first_month,\n",
    "        'name': 'cm_ensemble_identical',\n",
    "        'df_full': positive_integers(pd.read_parquet(filepath + 'bm_cm_ensemble_identical_expanded_' + str(year) + '.parquet'),colname),\n",
    "        'actuals': df_cm_actuals.loc[first_month: first_month + 12 - 1],\n",
    "    }\n",
    "    bm_cm_ensemble_identical.append(cm_e)\n",
    "    \n",
    "    cm_e = {\n",
    "        'year': year,\n",
    "        'first_month': first_month,\n",
    "        'name': 'cm_constituent_poisson',\n",
    "        'df_full': positive_integers(pd.read_parquet(filepath + 'bm_cm_constituent_poisson_expanded_' + str(year) + '.parquet'),colname),\n",
    "        'actuals': df_cm_actuals.loc[first_month: first_month + 12 - 1],\n",
    "    }\n",
    "    bm_cm_constituent_poisson.append(cm_e)\n",
    "    \n",
    "    cm_e = {\n",
    "        'year': year,\n",
    "        'first_month': first_month,\n",
    "        'name': 'cm_actuals_bootstrap',\n",
    "        'df_full': positive_integers(pd.read_parquet(filepath + 'bm_cm_bootstrap_expanded_' + str(year) + '.parquet'),colname),\n",
    "        'actuals': df_cm_actuals.loc[first_month: first_month + 12 - 1],\n",
    "    }\n",
    "    bm_cm_actuals_bootstrap.append(cm_e)\n",
    "    \n",
    "    if include_historical_values:\n",
    "        cm_hv = {\n",
    "            'year': year,\n",
    "            'first_month': first_month,\n",
    "            'name': 'cm_historical_poisson',\n",
    "            'df_full': positive_integers(pd.read_parquet(filepath + 'bm_cm_last_historical_poisson_expanded_' + str(year) + '.parquet'),colname),\n",
    "            'actuals': df_cm_actuals.loc[first_month: first_month + 12 - 1],\n",
    "        }\n",
    "        bm_cm_last_historical_poisson.append(cm_hv)\n",
    "        \n",
    "    if include_pgm:\n",
    "        pgm_e = {\n",
    "            'year': year,\n",
    "            'first_month': first_month,\n",
    "            'name': 'pgm_ensemble_poisson',\n",
    "            'df_full': positive_integers(pd.read_parquet(filepath + 'bm_pgm_ensemble_poisson_expanded_' + str(year) + '.parquet'),colname),\n",
    "            'actuals': df_pgm_actuals.loc[first_month: first_month + 12 - 1],\n",
    "        }\n",
    "        pgm_e['df_full'].index.set_names('priogrid_gid', level=1,inplace=True)\n",
    "        bm_pgm_ensemble_poisson.append(pgm_e)\n",
    "        \n",
    "        pgm_e = {\n",
    "            'year': year,\n",
    "            'first_month': first_month,\n",
    "            'name': 'pgm_ensemble_identical',\n",
    "            'df_full': positive_integers(pd.read_parquet(filepath + 'bm_pgm_ensemble_identical_expanded_' + str(year) + '.parquet'),colname),\n",
    "            'actuals': df_pgm_actuals.loc[first_month: first_month + 12 - 1],\n",
    "        }\n",
    "        pgm_e['df_full'].index.set_names('priogrid_gid', level=1,inplace=True)\n",
    "        bm_pgm_ensemble_identical.append(pgm_e)\n",
    "        \n",
    "    if False:\n",
    "        pgm_hv = {\n",
    "            'year': year,\n",
    "            'first_month': first_month,\n",
    "            'name': 'pgm_historical_values',\n",
    "            'df_full': positive_integers(pd.read_parquet(filepath + 'bm_pgm_historical_values_' + str(year) + '.parquet'),colname),\n",
    "\n",
    "            'actuals': df_pgm_actuals.loc[first_month: first_month + 12 - 1],\n",
    "        }\n",
    "        bm_pgm_historical_values.append(pgm_hv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9ddd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm_cm_ensemble_poisson[3]['df_full'].loc[494].loc[67].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9cb1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restructuring, evaluating:\n",
    "\n",
    "# Evaluation parameters:\n",
    "ign_bins = [0, 0.5, 2.5, 5.5, 10.5, 25.5, 50.5, 100.5, 250.5, 500.5, 1000.5]\n",
    "#ign_bins = [0, 0.5, 1000]\n",
    "#bm_cm_constituent_poisson,\n",
    "bm_list = [bm_pgm_ensemble_poisson, bm_pgm_ensemble_poisson, bm_cm_ensemble_poisson,bm_cm_ensemble_identical,bm_cm_last_historical_poisson,bm_cm_actuals_bootstrap]\n",
    "#bm_list = [bm_cm_ensemble_poisson,bm_cm_ensemble_identical,bm_cm_last_historical_poisson,bm_cm_actuals_bootstrap]\n",
    "\n",
    "# this is an absolute horror - need to make sure that spatial units correspond to bm_list\n",
    "spatial_units = ['priogrid_gid','priogrid_gid','country_id','country_id','country_id','country_id']\n",
    "\n",
    "for model_list,spatial_unit in zip(bm_list,spatial_units):\n",
    "    for item in model_list:\n",
    "        print(item['name'], item['year'])\n",
    "#        print(item['df_full'].query('draw == 0').describe())\n",
    "        item['observed'], item['predictions'] = structure_data(item['actuals'], item['df_full']) # structure data as xarrays that the xskillscore.crps_ensemble wants\n",
    "        item['crps'] = calculate_metrics(item['observed'], item['predictions'], metric = 'crps', aggregate_over=['month_id', spatial_unit]) # calculates crps.\n",
    "        item['crps_by_month'] = calculate_metrics(item['observed'], item['predictions'], metric = 'crps', aggregate_over=spatial_unit) # calculates crps.\n",
    "        item['crps_by_country'] = calculate_metrics(item['observed'], item['predictions'], metric = 'crps', aggregate_over='month_id') # calculates crps.\n",
    "        item['ign'] = calculate_metrics(item['observed'], item['predictions'], metric = \"ign\", bins = ign_bins, aggregate_over=['month_id', spatial_unit])\n",
    "        item['ign_by_month'] = calculate_metrics(item['observed'], item['predictions'], metric = \"ign\", bins = ign_bins, aggregate_over=spatial_unit)\n",
    "        item['ign_by_country'] = calculate_metrics(item['observed'], item['predictions'], metric = \"ign\", bins = ign_bins, aggregate_over='month_id')\n",
    "        item['mis'] = calculate_metrics(item['observed'], item['predictions'], metric = \"mis\", aggregate_over=['month_id', spatial_unit])\n",
    "        item['mis_by_month'] = calculate_metrics(item['observed'], item['predictions'], metric = \"mis\", aggregate_over=spatial_unit)\n",
    "        item['mis_by_country'] = calculate_metrics(item['observed'], item['predictions'], metric = \"mis\", aggregate_over='month_id')\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85543b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "countrylist.loc[246]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972b058a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "columns_to_plot = [\n",
    "    ('prediction',    '1%'),\n",
    "    ('prediction',    '5%'),\n",
    "    ('prediction',   '10%'),\n",
    "    ('prediction',   '20%'),\n",
    "    ('prediction',   '50%'),\n",
    "    ('prediction',   '80%'),\n",
    "    ('prediction',   '90%'),\n",
    "    ('prediction',   '95%'),\n",
    "    ('prediction',   '99%'),\n",
    "]\n",
    "ctp1 = [\n",
    "    ('prediction',  'mean'),]\n",
    "ctp2 = [(   'actuals',  'mean')] # Separate set for separate color/pattern\n",
    "\n",
    "\n",
    "for model_list in bm_list:\n",
    "    for item in model_list:\n",
    "        df_actuals = item['actuals'].reorder_levels(['country_id','month_id'])\n",
    "        df_actuals.rename(columns={'outcome':'actuals'},inplace=True)\n",
    "        df_full = item['df_full'].reorder_levels(['country_id','month_id','draw'])\n",
    "        df_full.rename(columns={'outcome':'prediction'},inplace=True)\n",
    "        df_merged = pd.merge(df_actuals, df_full,left_index=True,right_index=True)\n",
    "        for c in [(57,'Ethiopia'),(67,'Algeria'),(69,'Cameroon'),(131,'Saudi Arabia'),(246,'South Sudan')]:\n",
    "            title = 'Model ' + item['name'] + ', ' + c[1] + ' ' + str(item['year'])\n",
    "            fig, axs = plt.subplots(figsize=(16, 4))\n",
    "            df_description = df_merged.loc[c[0]].groupby('month_id').describe(percentiles=[.01,.05,.1,.2,.5,.8,.9,.95,.99])\n",
    "            df_description[columns_to_plot].plot(use_index=True,ylabel='Battle-related deaths',ax=axs,title=title,colormap='coolwarm')\n",
    "            df_description[ctp1].plot(ax=axs,color='gray',  linestyle='dashed', linewidth=2)\n",
    "            df_description[ctp2].plot(ax=axs,color='black', linewidth=3)\n",
    "            axs.legend(loc='center left', bbox_to_anchor=(1, 0.5), prop={'size':8})\n",
    "            fig.savefig(overleafpath_figures+'bm_predictions/'+'predictions_and_actuals_' + c[1] + '_' + str(item['year']) + '_' + item['name'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b39a757",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_description.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7077aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_plot = [\n",
    "    'actuals',\n",
    "    ('outcome',   '5%'),\n",
    "    ('outcome',   '10%'),\n",
    "    ('outcome',   '20%'),\n",
    "    ('outcome',   '50%'),\n",
    "    ('outcome',   '80%'),\n",
    "    ('outcome',   '90%'),\n",
    "    ('outcome',   '95%')]\n",
    "\n",
    "\n",
    "for c in [(57,'Ethiopia'),(69,'xx'),(130,'yy'),(246,'zz')]:\n",
    "    \n",
    "    df_country = item['df_full'].query(f'country_id=={c[0]}')\n",
    "    df_actuals = item['actuals'].query(f'country_id=={c[0]}')\n",
    "    df_actuals['actuals'] = df_actuals['outcome']\n",
    "    df_description = df_country.groupby('month_id').describe(percentiles=[.05,.1,.2,.5,.8,.9,.95])\n",
    "#    df_description.reset_index(inplace=True)\n",
    "    df_joined = pd.concat([df_actuals,df_description], ignore_index=True)\n",
    "\n",
    "    df_joined[columns_to_plot].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64105e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "item['df_full']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7195d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joined = pd.concat([df_actuals,df_description], ignore_index=True)\n",
    "df_joined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f4d9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_actuals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7561025",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_actuals.describe(), df_description.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386f0c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_description.head())\n",
    "x = df_description['month_id']\n",
    "y=df_description[('outcome',   '10%')]\n",
    "z=df_description[('outcome',   '90%')]\n",
    "plt.plot(x,y,z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041f0b91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acbc886",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bce8642",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.percentile?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7296cdef",
   "metadata": {},
   "source": [
    "# Assembling evaluation tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b30e994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create table A for each model with:\n",
    "# one row for each year plus one for mean over years\n",
    "# one col for crps \n",
    "# one col for ign \n",
    "# one col for mis\n",
    "# Create table B with the same, but metrics per month\n",
    "\n",
    "# Table A:\n",
    "for model_list in bm_list:\n",
    "    year_list = []\n",
    "    for item in model_list:\n",
    "        metrics = pd.concat([item['crps'],item['ign'],item['mis']],axis=1)\n",
    "        metrics['year'] = item['year']\n",
    "        year_list.append(metrics)\n",
    "    table_annual = pd.concat(year_list,axis=0)   \n",
    "    table_annual.set_index(str('year'),inplace=True)\n",
    "    table_annual.loc['Mean'] = table_annual.mean()\n",
    "    table_filename = overleafpath + 'bm_evaluation/' + item['name'] + '_aggregated' + '.tex'\n",
    "    with open(table_filename, 'w') as tf:\n",
    "        tf.write(table_annual.to_latex(float_format=\"{:.2f}\".format))\n",
    "\n",
    "# Table B:\n",
    "for model_list in bm_list:\n",
    "    year_list = []\n",
    "    for item in model_list:\n",
    "        metrics = pd.concat([item['crps_by_month'],item['ign_by_month'],item['mis_by_month']],axis=1)\n",
    "        metrics['month'] = metrics.index - (item['year']-1980)*12\n",
    "        metrics['month'] = metrics['month'].astype(int)\n",
    "        metrics['year'] = item['year']\n",
    "        year_list.append(metrics)\n",
    "    table_monthly = pd.concat(year_list,axis=0)   \n",
    "    table_monthly.set_index(['year','month'],inplace=True)\n",
    "    table_monthly_aggregated = table_monthly.groupby('month').agg('mean')\n",
    "    #table.loc['Mean'] = table.mean()\n",
    "    table_filename = overleafpath + 'bm_evaluation/' + item['name'] + '_monthly' + '.tex'\n",
    "    with open(table_filename, 'w') as tf:\n",
    "        tf.write(table_monthly_aggregated.to_latex(float_format=\"{:.2f}\".format))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c973b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_annual.to_latex(float_format=\"{:.2f}\".format,column_format='lrrr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba48cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics['month'] = metrics.index - (2021-1980)*12\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2aebce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking whether balanced panel:\n",
    "\n",
    "if include_historical_values:\n",
    "    print(bm_cm_historical_values[0]['df_full'].head())\n",
    "    print('Number of missing?',bm_cm_historical_values[0]['df_full'].isnull().sum())\n",
    "    print(bm_cm_historical_values[0]['df_full'].describe())\n",
    "    for m in range(445,457):\n",
    "        df = bm_cm_historical_values[0]['df_full'].loc[m]\n",
    "        print(m,len(df))\n",
    "        df2 =df.groupby([\"country_id\"]).agg({'prediction': [\"count\"]})\n",
    "        print(df2.describe())\n",
    "    print(990*2292)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705c5fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if include_historical_values:\n",
    "    print(bm_cm_historical_values[0]['df_full'].describe())\n",
    "    print(bm_cm_historical_values[0]['df_full'].query('draw == 0').describe())\n",
    "    print(bm_cm_historical_values[0]['df_full'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95e995b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm_pgm_ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e559c6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(item['df_full']))\n",
    "print(len(item['df_full'])/12)\n",
    "print(len(item['df_full'])/(12*990))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17466c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IgnoranceScore import ensemble_ignorance_score, _ensemble_ignorance_score\n",
    "import numpy as np\n",
    "observations = [0, 1, 50, 500]\n",
    "forecasts = np.array([[0, 0, 0, 0, 0],\n",
    "                      [1, 1, 1, 2, 55],\n",
    "                      [500, 49, 52, 52, 500],\n",
    "                      [49, 49, 49, 49, 500]])\n",
    "bins = [0, 0.5, 10.5, 50.5, 100.5, 1000.5]\n",
    "res = ensemble_ignorance_score(observations, forecasts, prob_type=3, ign_max=None, round_values=False, axis=-1, bins = bins, low_bin=0, high_bin=1000)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f9b1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from CompetitionEvaluation import load_data, structure_data, calculate_metrics\n",
    " \n",
    "observed, predictions = load_data(forecasts_path=filepath + \"cm_benchmark_ensemble_550.parquet\",\n",
    "                                    observed_path=filepath + \"cm_actuals.parquet\")\n",
    "predictions[\"prediction\"] = predictions[\"prediction\"].replace(-1, 0)\n",
    "observed, predictions = structure_data(observed, predictions)\n",
    "metrics = calculate_metrics(observed, predictions, metric = \"ign\", round_values = True)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055b457f",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(calculate_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7781c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "\n",
    "#observed, predictions = load_data(args.o, args.p) # read parquet files to pandas\n",
    "observed, predictions = structure_data(df_pgm_actuals, df_bm_pgm_historical_values) # structure data as xarrays that the xskillscore.crps_ensemble wants\n",
    "metrics = calculate_metrics(observed, predictions) # calculates crps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d4d1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bm_cm_ensemble = pd.read_parquet(filepath + 'cm_benchmark_ensemble_550.parquet')\n",
    "df_bm_cm_ensemble.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd111b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bm_cm_ensemble.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7805136d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49577f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bm_pgm_historical_values = pd.read_parquet(filepath + 'pgm_benchmark_historical_values_step_3.parquet')\n",
    "df_bm_pgm_historical_values.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bd7776",
   "metadata": {},
   "outputs": [],
   "source": [
    "#observed, predictions = load_data(args.o, args.p) # read parquet files to pandas\n",
    "observed, predictions = structure_data(df_cm_actuals, df_bm_cm_ensemble) # structure data as xarrays that the xskillscore.crps_ensemble wants\n",
    "metrics = calculate_metrics(observed, predictions) # calculates crps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97da38f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747a07aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in for all 12 steps\n",
    "from datetime import datetime\n",
    "print(\"Cell started to run:\", datetime.now())\n",
    "\n",
    "df_pgm_hv = []\n",
    "for step in range(3,14+1):\n",
    "    df = pd.read_parquet(filepath + 'pgm_benchmark_historical_values_step_' + str(step) + '.parquet')\n",
    "    print(step, df.describe())\n",
    "    df_pgm_hv.append(df)\n",
    "    \n",
    "print(\"Cell run ended:\", datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f0e8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cell started to run:\", datetime.now())\n",
    "i = 3\n",
    "for df in df_pgm_hv:\n",
    "    print('step',i,datetime.now())\n",
    "    observed, predictions = structure_data(df_pgm_actuals, df) # structure data as xarrays that the xskillscore.crps_ensemble wants\n",
    "    metrics = calculate_metrics(observed, predictions) # calculates crps.\n",
    "    print(metrics)\n",
    "    i=i+1\n",
    "print(\"Cell run ended:\", datetime.now())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138b41a7",
   "metadata": {},
   "source": [
    "# Read in the sc-type prediction files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e8ac36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bm_pgm_ensemble2022 = pd.read_parquet(filepath + 'bm_pgm_ensemble_2022.parquet')\n",
    "df_pgm_actuals_2022 = df_pgm_actuals.loc[505:516]\n",
    "df_bm_pgm_ensemble2022.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43d47e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "observed, predictions = structure_data(df_pgm_actuals_2022, df_bm_pgm_ensemble2022) # structure data as xarrays that the xskillscore.crps_ensemble wants\n",
    "metrics = calculate_metrics(observed, predictions) # calculates crps.\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65dc5cc",
   "metadata": {},
   "source": [
    "# Creating samples based on point predictions\n",
    "\n",
    "Assuming Poisson distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c88a578",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_ensemble_aggregated = pd.read_parquet(filepath + 'cm_benchmark_ensemble_550_aggregated.parquet')\n",
    "\n",
    "print(cm_ensemble_aggregated.describe())\n",
    "print(cm_ensemble_aggregated.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec01cd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip down to a year of sc predictions:\n",
    "df_cm_ensemble = []\n",
    "for step in range(3,14+1):\n",
    "    df = cm_ensemble_aggregated['mean_log_prediction'].loc[442+step]\n",
    "    df = pd.DataFrame(df[df.index.get_level_values('step').isin([step])])\n",
    "    df['prediction'] = np.expm1(df['mean_log_prediction'])\n",
    "    df_cm_ensemble.append(df)\n",
    "\n",
    "df_cm_ensemble_stripped = pd.concat(df_cm_ensemble)\n",
    "print(df_cm_ensemble_stripped.describe())\n",
    "print(df_cm_ensemble_stripped.tail(40))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c3d283",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
